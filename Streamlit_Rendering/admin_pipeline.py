# Streamlit_Rendering/admin_pipeline.py

import json
import pandas as pd
import numpy as np
import streamlit as st
from typing import List, Dict, Any # í˜¸í™˜ì„±ì„ ìœ„í•´ ì¶”ê°€

from Streamlit_Rendering.crawl import fetch_article_from_url
from Streamlit_Rendering import repo
# summary.pyì—ì„œ í´ëž˜ìŠ¤ì™€ ë”ë¯¸ í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°
from Streamlit_Rendering.summary import FastKoBertSummarizer, summarize_text_dummy
from Streamlit_Rendering.trust import score_trust_dummy

# --------------------------------------------------------------------------
# 1. ëª¨ë¸ ìºì‹±
# --------------------------------------------------------------------------
@st.cache_resource
def load_summarizer_model():
    """
    FastKoBertSummarizer ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— í•œ ë²ˆë§Œ ì˜¬ë¦¬ê³  ìž¬ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    print("ðŸš€ Loading FastKoBertSummarizer... (First time only)")
    model = FastKoBertSummarizer()
    return model

# --------------------------------------------------------------------------
# 2. ë©”ì¸ ë¡œì§
# --------------------------------------------------------------------------

ARTICLE_COLUMNS = [
    "article_id", "title", "source", "url", "published_at", "full_text",
    "summary_text", "keywords", "embed_full", "embed_summary",
    "trust_score", "trust_verdict", "trust_reason", "trust_per_criteria",
    "status",
]

def ingest_one_url(url: str, source: str = "manual", dedup_by_url: bool = True) -> Dict[str, Any]:
    """
    URL 1ê°œ â†’ í¬ë¡¤ë§ â†’ (ì¤‘ë³µ í•„í„°ë§) â†’ ëª¨ë¸ ë¶„ì„ â†’ DB ì ìž¬
    """
    try:
        # 1. ì¤‘ë³µ ì²´í¬
        if dedup_by_url and repo.exists_article_url(url):
            return {"status": "skipped", "message": "ì´ë¯¸ DBì— ì¡´ìž¬í•˜ëŠ” URLìž…ë‹ˆë‹¤. (ì¤‘ë³µ ìŠ¤í‚µ)", "url": url}

        # 2. í¬ë¡¤ë§
        df_raw = fetch_article_from_url(url=url, source=source)
        
        # 3. ë°ì´í„° ê°€ê³µ ë° ëª¨ë¸ ì‹¤í–‰
        df_ready = build_ready_rows(df_raw)

        # 4. DB ì ìž¬
        repo.upsert_articles(df_ready)
        return {"status": "inserted", "message": "DBì— 1ê±´ ì ìž¬ë˜ì—ˆìŠµë‹ˆë‹¤.", "url": url}

    except Exception as e:
        return {"status": "error", "message": f"í¬ë¡¤ë§/ì ìž¬ ì‹¤íŒ¨: {e}", "url": url}


def build_ready_rows(df_raw: pd.DataFrame) -> pd.DataFrame:
    """
    í¬ë¡¤ë§ëœ ë°ì´í„°ë¥¼ ë°›ì•„ ëª¨ë¸ì„ ëŒë ¤ ìš”ì•½, í‚¤ì›Œë“œ, ìž„ë² ë”©ì„ ì±„ì›Œ ë„£ìŠµë‹ˆë‹¤.
    """
    # ìºì‹±ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    model = load_summarizer_model()
    
    rows = []
    for _, r in df_raw.iterrows():
        full_text = str(r["full_text"])
        source = str(r["source"])
        
        try:
            # ëª¨ë¸ ë¶„ì„ (ìš”ì•½, í‚¤ì›Œë“œ, ìž„ë² ë”© ë“± í•œ ë²ˆì— ì¶”ì¶œ)
            summary, keywords, content_emb, keyword_emb, summary_emb, trust_score_model = model.analyze_single(full_text)
            
            # Numpy ë°°ì—´ -> List ë³€í™˜ (JSON ì €ìž¥ìš©)
            # hasattr ì²´í¬ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
            embed_full_list = content_emb.tolist() if hasattr(content_emb, 'tolist') else []
            embed_summary_list = summary_emb.tolist() if hasattr(summary_emb, 'tolist') else []
            
        except Exception as e:
            print(f"âŒ Model Analysis Error: {e}")
            summary = summarize_text_dummy(full_text)
            keywords = []
            embed_full_list = []
            embed_summary_list = []
            trust_score_model = 50

        # ì‹ ë¢°ë„ í‰ê°€
        trust_detail = score_trust_dummy(full_text, source=source, low=30, high=100)
        final_trust_score = int(trust_score_model)

        rows.append({
            "article_id": str(r["article_id"]),
            "title": str(r["title"]),
            "source": source,
            "url": str(r["url"]),
            "published_at": str(r["published_at"]),
            "full_text": full_text,

            "summary_text": summary,
            "keywords": json.dumps(keywords, ensure_ascii=False),
            "embed_full": json.dumps(embed_full_list),
            "embed_summary": json.dumps(embed_summary_list),

            "trust_score": final_trust_score,
            "trust_verdict": trust_detail.get("verdict", "uncertain"),
            "trust_reason": trust_detail.get("reason", ""),
            "trust_per_criteria": json.dumps(trust_detail.get("per_criteria", {}), ensure_ascii=False),

            "status": "ready",
        })

    df_ready = pd.DataFrame(rows).reindex(columns=ARTICLE_COLUMNS)
    return df_ready

# --------------------------------------------------------------------------
# ê°œë³„ í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜ (íƒ€ìž… ížŒíŠ¸ ìˆ˜ì •ë¨)
# --------------------------------------------------------------------------

def run_summary(full_text: str) -> str:
    model = load_summarizer_model()
    summary, _, _, _, _, _ = model.analyze_single(full_text)
    return summary

def run_keywords(full_text: str) -> List[str]: # list[str] -> List[str] ë¡œ ë³€ê²½
    model = load_summarizer_model()
    _, keywords, _, _, _, _ = model.analyze_single(full_text)
    return keywords

def run_embedding(text: str) -> List[float]: # list[float] -> List[float] ë¡œ ë³€ê²½
    model = load_summarizer_model()
    emb = model.get_embedding_batch([text])[0]
    return emb.tolist()

def run_trust(full_text: str, source: str) -> dict:
    return score_trust_dummy(full_text, source=source, low=30, high=100)
